{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"Bq3fi1cyKJee","colab":{"base_uri":"https://localhost:8080/"},"outputId":"414dda40-a839-4f81-c23f-aa4db1ebab65"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["# If in Colab, then import the drive module from google.colab\n","if 'google.colab' in str(get_ipython()):\n","  from google.colab import drive\n","  # Mount the Google Drive to access files stored there\n","  drive.mount('/content/drive')\n","\n","  # Install the latest version of torchtext library quietly without showing output\n","\n","  !pip install torchinfo -qq\n","\n","  basepath = '/content/drive/MyDrive/NLP UTD/'\n","\n"]},{"cell_type":"code","source":["# Importing PyTorch library for tensor computations and neural network modules\n","import torch\n","import torch.nn as nn\n","\n","# For working with textual data vocabularies and for displaying model summaries\n","\n","# General-purpose Python libraries for random number generation and numerical operations\n","import random\n","import numpy as np\n","\n","# Utilities for efficient serialization/deserialization of Python objects and for element tallying\n","import joblib\n","from collections import Counter\n","\n","# For creating lightweight attribute classes and for partial function application\n","from functools import partial\n","\n","# For filesystem path handling, generating and displaying confusion matrices, and date-time manipulations\n","from pathlib import Path\n","from sklearn.metrics import confusion_matrix\n","from datetime import datetime\n","\n","# For plotting and visualization\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","# %matplotlib inline\n","\n","### NEW ##########################\n","# imports from Huggingface ecosystem\n","from transformers.modeling_outputs import SequenceClassifierOutput\n","from transformers import PreTrainedModel, PretrainedConfig\n","from transformers import TrainingArguments, Trainer"],"metadata":{"id":"H_HsPG8gNlXo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Set the base folder path using the Path class for better path handling\n","base_folder = Path(basepath)\n","\n","# Define the data folder path by appending the relative path to the base folder\n","# This is where the data files will be stored\n","data_folder = base_folder / 'datasets'\n","\n","# Define the model folder path for saving trained models\n","# This path points to a specific folder designated for NLP models related to the IMDb dataset\n","model_folder = base_folder / 'models'\n","\n","custom_functions = base_folder/'custom-functions'\n"],"metadata":{"id":"3lD57zUpNcfP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Step 2: Import pandas and other necessary libraries\n","import pandas as pd\n","import os  # Importing os for checking the current directory\n","from pathlib import Path  # Importing Path to handle file paths\n"],"metadata":{"id":"OTBJduPZTKvW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_data=pd.read_csv(data_folder/'train.csv')\n"],"metadata":{"id":"hbBk6qgSUwsD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_data.head()"],"metadata":{"id":"vnssxTu4TKmP","colab":{"base_uri":"https://localhost:8080/","height":206},"outputId":"dc7aad62-c193-4019-cb64-cda434c941f9"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["           ID                                              Tweet  anger  \\\n","0  2017-21441  “Worry is a down payment on a problem you may ...      0   \n","1  2017-31535  Whatever you decide to do make sure it makes y...      0   \n","2  2017-21068  @Max_Kellerman  it also helps that the majorit...      1   \n","3  2017-31436  Accept the challenges so that you can literall...      0   \n","4  2017-22195  My roommate: it's okay that we can't spell bec...      1   \n","\n","   anticipation  disgust  fear  joy  love  optimism  pessimism  sadness  \\\n","0             1        0     0    0     0         1          0        0   \n","1             0        0     0    1     1         1          0        0   \n","2             0        1     0    1     0         1          0        0   \n","3             0        0     0    1     0         1          0        0   \n","4             0        1     0    0     0         0          0        0   \n","\n","   surprise  trust  \n","0         0      1  \n","1         0      0  \n","2         0      0  \n","3         0      0  \n","4         0      0  "],"text/html":["\n","  <div id=\"df-184b2a29-3ea6-44aa-b6b3-c5f89fa3627f\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ID</th>\n","      <th>Tweet</th>\n","      <th>anger</th>\n","      <th>anticipation</th>\n","      <th>disgust</th>\n","      <th>fear</th>\n","      <th>joy</th>\n","      <th>love</th>\n","      <th>optimism</th>\n","      <th>pessimism</th>\n","      <th>sadness</th>\n","      <th>surprise</th>\n","      <th>trust</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2017-21441</td>\n","      <td>“Worry is a down payment on a problem you may ...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2017-31535</td>\n","      <td>Whatever you decide to do make sure it makes y...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2017-21068</td>\n","      <td>@Max_Kellerman  it also helps that the majorit...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2017-31436</td>\n","      <td>Accept the challenges so that you can literall...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2017-22195</td>\n","      <td>My roommate: it's okay that we can't spell bec...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-184b2a29-3ea6-44aa-b6b3-c5f89fa3627f')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-184b2a29-3ea6-44aa-b6b3-c5f89fa3627f button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-184b2a29-3ea6-44aa-b6b3-c5f89fa3627f');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-59727fa9-ef4b-4de8-b962-4e69366d23a1\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-59727fa9-ef4b-4de8-b962-4e69366d23a1')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-59727fa9-ef4b-4de8-b962-4e69366d23a1 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"train_data","summary":"{\n  \"name\": \"train_data\",\n  \"rows\": 7724,\n  \"fields\": [\n    {\n      \"column\": \"ID\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7724,\n        \"samples\": [\n          \"2017-30250\",\n          \"2017-30519\",\n          \"2018-01720\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Tweet\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7724,\n        \"samples\": [\n          \"I'm due for a big change! I've prayed on it, I think I deserve it #positivity \",\n          \"incetown, age 23, joyful, elevated in hope with the\",\n          \"Never heard of #CaraCaraOranges until today. Very #tasty! I highly recommend them! #delicious #GoodForYou #fruits  #oranges\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"anger\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"anticipation\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"disgust\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fear\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"joy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"love\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"optimism\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pessimism\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sadness\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"surprise\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"trust\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":130}]},{"cell_type":"code","source":["import re\n","def clean_text(text):\n","    # Remove URLs\n","    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n","    # Remove special characters and punctuation\n","    text = re.sub(r'\\W', ' ', text)\n","    # Remove single characters\n","    text = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', text)\n","    # Remove extra spaces\n","    text = re.sub(r'\\s+', ' ', text)\n","    return text\n"],"metadata":{"id":"Bqbsw4aKwWYY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_data['Tweet'] = train_data['Tweet'].apply(clean_text)"],"metadata":{"id":"kUGTTQ94wmAH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","# First split: 60% training and 40% (test + validation)\n","train_data, val_data = train_test_split(train_data, test_size=0.2, random_state=42)\n","\n","# Check the shapes of the new datasets\n","print(f\"Training Data Shape: {train_data.shape}\")\n","print(f\"Validation Data Shape: {val_data.shape}\")"],"metadata":{"id":"RUL6H_tGTKgO","colab":{"base_uri":"https://localhost:8080/"},"outputId":"8f5150bd-9a60-4ee5-a23a-2367833ae8f7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Training Data Shape: (6179, 13)\n","Validation Data Shape: (1545, 13)\n"]}]},{"cell_type":"code","source":["train_data.shape,val_data.shape"],"metadata":{"id":"pIwigAE3TKdc","colab":{"base_uri":"https://localhost:8080/"},"outputId":"13aa498c-8c1d-4aa1-b7e5-032796761f47"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((6179, 13), (1545, 13))"]},"metadata":{},"execution_count":134}]},{"cell_type":"code","source":["!pip install datasets"],"metadata":{"id":"Pl82MNwqR1z7","colab":{"base_uri":"https://localhost:8080/"},"outputId":"00056842-5db2-4e87-959b-f3a6aacae799"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.0.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (16.1.0)\n","Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n","Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n","Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.5)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n","Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.9)\n","Requirement already satisfied: huggingface-hub>=0.22.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.24.7)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.3)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n","Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.13.1)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.22.0->datasets) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"]}]},{"cell_type":"code","source":["X_train=train_data['Tweet']\n","X_val=val_data['Tweet']"],"metadata":{"id":"g_HW6fanp_kj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_train = train_data[['anger', 'anticipation', 'disgust', 'fear', 'joy', 'love',\n","                    'optimism', 'pessimism', 'sadness', 'surprise', 'trust']].values.tolist()\n","\n","y_valid = val_data[['anger', 'anticipation', 'disgust', 'fear', 'joy', 'love',\n","                    'optimism', 'pessimism', 'sadness', 'surprise', 'trust']].values.tolist()"],"metadata":{"id":"7kUVq6faqRJv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from datasets import Dataset"],"metadata":{"id":"HeGrSC8F0gCo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["trainset = Dataset.from_dict({\n","    'texts': X_train,  # Your cleaned text data for training\n","    'labels': y_train           # Your multilabels for training\n","})\n","\n","validset = Dataset.from_dict({\n","    'texts': X_val,  # Your cleaned text data for validation\n","    'labels': y_valid           # Your multilabels for validation\n","})"],"metadata":{"id":"B4IhBlEIpODW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from transformers import PretrainedConfig\n","\n","class CustomConfig(PretrainedConfig):\n","    def __init__(self, vocab_size=0, embedding_dim=0, hidden_dim1=0, hidden_dim2=0, num_labels=11, **kwargs):\n","        super().__init__(**kwargs)\n","        self.vocab_size = vocab_size\n","        self.embedding_dim = embedding_dim\n","        self.hidden_dim1 = hidden_dim1\n","        self.hidden_dim2 = hidden_dim2\n","        self.num_labels = num_labels"],"metadata":{"id":"_azzj45UrYbI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","from transformers import PreTrainedModel\n","from transformers.modeling_outputs import SequenceClassifierOutput\n","\n","class CustomMLP(PreTrainedModel):\n","    config_class = CustomConfig\n","\n","    def __init__(self, config):\n","        super().__init__(config)\n","\n","        self.embedding_bag = nn.EmbeddingBag(config.vocab_size, config.embedding_dim)\n","        self.layers = nn.Sequential(\n","            nn.Linear(config.embedding_dim, config.hidden_dim1),\n","            nn.BatchNorm1d(num_features=config.hidden_dim1),\n","            nn.ReLU(),\n","            nn.Dropout(p=0.5),\n","            nn.Linear(config.hidden_dim1, config.hidden_dim2),\n","            nn.BatchNorm1d(num_features=config.hidden_dim2),\n","            nn.ReLU(),\n","            nn.Dropout(p=0.5),\n","            nn.Linear(config.hidden_dim2, 11)  # Output layer\n","        )\n","\n","    def forward(self, input_ids, offsets, labels=None):\n","      embed_out = self.embedding_bag(input_ids, offsets)\n","      logits = self.layers(embed_out)\n","      loss = None\n","      if labels is not None:\n","        loss_fct = nn.BCEWithLogitsLoss()\n","        loss = loss_fct(logits, labels.float())  # Ensure labels are float type\n","      return SequenceClassifierOutput(\n","        loss=loss,\n","        logits=logits\n","    )\n"],"metadata":{"id":"d-PSiJw2rws3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from collections import Counter, OrderedDict\n","from typing import Dict, List, Optional, Union\n","\n","class Vocab:\n","    def __init__(self, tokens: List[str]) -> None:\n","        self.itos: List[str] = tokens\n","        self.stoi: Dict[str, int] = {token: i for i, token in enumerate(tokens)}\n","        self.default_index: Optional[int] = None\n","\n","    def __getitem__(self, token: str) -> int:\n","        if token in self.stoi:\n","            return self.stoi[token]\n","        if self.default_index is not None:\n","            return self.default_index\n","        raise RuntimeError(f\"Token '{token}' not found in vocab\")\n","\n","    def __contains__(self, token: str) -> bool:\n","        return token in self.stoi\n","\n","    def __len__(self) -> int:\n","        return len(self.itos)\n","\n","    def insert_token(self, token: str, index: int) -> None:\n","        if index < 0 or index > len(self.itos):\n","            raise ValueError(\"Index out of range\")\n","        if token in self.stoi:\n","            old_index = self.stoi[token]\n","            if old_index < index:\n","                self.itos.pop(old_index)\n","                self.itos.insert(index - 1, token)\n","            else:\n","                self.itos.pop(old_index)\n","                self.itos.insert(index, token)\n","        else:\n","            self.itos.insert(index, token)\n","\n","        self.stoi = {token: i for i, token in enumerate(self.itos)}\n","\n","    def append_token(self, token: str) -> None:\n","        if token in self.stoi:\n","            raise RuntimeError(f\"Token '{token}' already exists in the vocab\")\n","        self.insert_token(token, len(self.itos))\n","\n","    def set_default_index(self, index: Optional[int]) -> None:\n","        self.default_index = index\n","\n","    def get_default_index(self) -> Optional[int]:\n","        return self.default_index\n","\n","    def lookup_token(self, index: int) -> str:\n","        if 0 <= index < len(self.itos):\n","            return self.itos[index]\n","        raise RuntimeError(f\"Index {index} out of range\")\n","\n","    def lookup_tokens(self, indices: List[int]) -> List[str]:\n","        return [self.lookup_token(index) for index in indices]\n","\n","    def lookup_indices(self, tokens: List[str]) -> List[int]:\n","        return [self[token] for token in tokens]\n","\n","    def get_stoi(self) -> Dict[str, int]:\n","        return self.stoi.copy()\n","\n","    def get_itos(self) -> List[str]:\n","        return self.itos.copy()\n","\n","    @classmethod\n","    def vocab(cls, ordered_dict: Union[OrderedDict, Counter], min_freq: int = 1, specials: Optional[List[str]] = None, special_first: bool = True) -> 'Vocab':\n","        specials = specials or []\n","        for token in specials:\n","            ordered_dict.pop(token, None)\n","\n","        tokens = [token for token, freq in ordered_dict.items() if freq >= min_freq]\n","\n","        if special_first:\n","            tokens = specials + tokens\n","        else:\n","            tokens = tokens + specials\n","\n","        return cls(tokens)"],"metadata":{"id":"Q8cRbwEjr2Eg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_vocab(dataset, min_freq=1):\n","    \"\"\"\n","    Generate a vocabulary from a dataset.\n","\n","    Args:\n","        dataset (Dataset): A Hugging Face Dataset object. The dataset should\n","                           have a key 'texts' that contains the text data.\n","        min_freq (int): The minimum frequency for a token to be included in\n","                        the vocabulary.\n","\n","    Returns:\n","        torchtext.vocab.Vocab: Vocabulary object containing tokens from the\n","                               dataset that meet or exceed the specified\n","                               minimum frequency. It also includes a special\n","                               '<unk>' token for unknown words.\n","    \"\"\"\n","    # Initialize a counter object to hold token frequencies\n","    counter = Counter()\n","\n","    # Update the counter with tokens from each text in the dataset\n","    # Iterating through texts in the dataset\n","    for text in dataset['texts']:  ###### Change from previous function ####\n","        counter.update(str(text).split())\n","\n","    # Create a vocabulary using the counter object\n","    # Tokens that appear fewer times than `min_freq` are excluded\n","    my_vocab = Vocab.vocab(counter, min_freq=min_freq)\n","\n","    # Insert a '<unk>' token at index 0 to represent unknown words\n","    my_vocab.insert_token('<unk>', 0)\n","\n","    # Set the default index to 0\n","    # This ensures that any unknown word will be mapped to '<unk>'\n","    my_vocab.set_default_index(0)\n","\n","    return my_vocab"],"metadata":{"id":"YO7uuBErr5ID"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Creating a function that will be used to get the indices of words from vocab\n","def tokenizer(text, vocab):\n","    \"\"\"Converts text to a list of indices using a vocabulary dictionary\"\"\"\n","    return [vocab[token] for token in str(text).split()]"],"metadata":{"id":"p1JBCPUWr7mw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","import numpy as np\n","\n","def collate_batch(batch, my_vocab):\n","    \"\"\"\n","    Prepares a batch of data by transforming texts into indices based on a vocabulary and\n","    converting labels into a tensor for multilabel classification.\n","\n","    Args:\n","        batch (list of dict): A batch of data where each element is a dictionary with keys\n","                              'labels' and 'texts'. 'labels' are the multilabels, and\n","                              'texts' are the corresponding texts.\n","        my_vocab (torchtext.vocab.Vocab): A vocabulary object that maps tokens to indices.\n","\n","    Returns:\n","        dict: A dictionary with three keys:\n","              - 'input_ids': a tensor containing concatenated indices of the texts.\n","              - 'offsets': a tensor representing the starting index of each text in 'input_ids'.\n","              - 'labels': a tensor of the labels for each text in the batch.\n","\n","    The function transforms each text into a list of indices based on the provided vocabulary.\n","    It also converts the labels into a tensor. The 'offsets' are computed to keep track of the\n","    start of each text within the 'input_ids' tensor, which is a flattened representation of all text indices.\n","    \"\"\"\n","\n","    # Get labels and texts from batch dict samples\n","    labels = [sample['labels'] for sample in batch]  # List of lists containing binary labels\n","    texts = [sample['texts'] for sample in batch]    # List of texts\n","\n","    # Convert the list of labels into a tensor of dtype int32 for multilabel classification\n","    labels_tensor = torch.tensor(labels, dtype=torch.int32)  # Use int32 for compatibility with multilabel tasks\n","\n","    # Convert the list of texts into a list of lists; each inner list contains the vocabulary indices for a text\n","    list_of_list_of_indices = [tokenizer(text, my_vocab) for text in texts]\n","\n","    # Concatenate all text indices into a single tensor\n","    input_ids = torch.cat([torch.tensor(indices, dtype=torch.int64) for indices in list_of_list_of_indices])\n","\n","    # Compute the offsets for each text in the concatenated tensor\n","    offsets = [0] + list(np.cumsum([len(indices) for indices in list_of_list_of_indices]))  # Cumulative lengths\n","    offsets = torch.tensor(offsets[:-1])  # Exclude the last cumulative sum since it's the end\n","\n","    return {\n","        'input_ids': input_ids,\n","        'offsets': offsets,\n","        'labels': labels_tensor\n","    }\n"],"metadata":{"id":"TJ92vm2Qr-Ux"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["multi_vocab = get_vocab(trainset, min_freq=2)\n","collate_fn = partial(collate_batch, my_vocab=multi_vocab)"],"metadata":{"id":"nMqM7hYLsBIS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["my_config = CustomConfig(vocab_size=len(multi_vocab),\n","                         embedding_dim=300,\n","                         hidden_dim1=200,\n","                         hidden_dim2=100,\n","                         num_labels=11)  # Update to the total number of unique labels\n"],"metadata":{"id":"qL4Imv2esDPg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["my_config.id2label={\n","    0: 'anger',\n","    1: 'anticipation',\n","    2: 'disgust',\n","    3: 'fear',\n","    4: 'joy',\n","    5: 'love',\n","    6: 'optimism',\n","    7: 'pessimism',\n","    8: 'sadness',\n","    9: 'surprise',\n","    10: 'trust'\n","}"],"metadata":{"id":"mxvNzecOGXze"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["my_config"],"metadata":{"id":"G8eOlC-bsGBc","colab":{"base_uri":"https://localhost:8080/"},"outputId":"e150d408-ea3f-4e60-c10b-d9ae9c296541"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["CustomConfig {\n","  \"embedding_dim\": 300,\n","  \"hidden_dim1\": 200,\n","  \"hidden_dim2\": 100,\n","  \"id2label\": {\n","    \"0\": \"anger\",\n","    \"1\": \"anticipation\",\n","    \"2\": \"disgust\",\n","    \"3\": \"fear\",\n","    \"4\": \"joy\",\n","    \"5\": \"love\",\n","    \"6\": \"optimism\",\n","    \"7\": \"pessimism\",\n","    \"8\": \"sadness\",\n","    \"9\": \"surprise\",\n","    \"10\": \"trust\"\n","  },\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_10\": 10,\n","    \"LABEL_2\": 2,\n","    \"LABEL_3\": 3,\n","    \"LABEL_4\": 4,\n","    \"LABEL_5\": 5,\n","    \"LABEL_6\": 6,\n","    \"LABEL_7\": 7,\n","    \"LABEL_8\": 8,\n","    \"LABEL_9\": 9\n","  },\n","  \"transformers_version\": \"4.44.2\",\n","  \"vocab_size\": 6945\n","}"]},"metadata":{},"execution_count":149}]},{"cell_type":"code","source":["# Generating id_to_label by reversing the key-value pairs in label_to_id\n","my_config.label2id = {v: k for k, v in my_config.id2label .items()}"],"metadata":{"id":"PLO5jLhUsPO8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["my_config"],"metadata":{"id":"tXtDaErNsRrW","colab":{"base_uri":"https://localhost:8080/"},"outputId":"8d8df664-cdc9-404e-9de1-dc49237e2439"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["CustomConfig {\n","  \"embedding_dim\": 300,\n","  \"hidden_dim1\": 200,\n","  \"hidden_dim2\": 100,\n","  \"id2label\": {\n","    \"0\": \"anger\",\n","    \"1\": \"anticipation\",\n","    \"2\": \"disgust\",\n","    \"3\": \"fear\",\n","    \"4\": \"joy\",\n","    \"5\": \"love\",\n","    \"6\": \"optimism\",\n","    \"7\": \"pessimism\",\n","    \"8\": \"sadness\",\n","    \"9\": \"surprise\",\n","    \"10\": \"trust\"\n","  },\n","  \"label2id\": {\n","    \"anger\": 0,\n","    \"anticipation\": 1,\n","    \"disgust\": 2,\n","    \"fear\": 3,\n","    \"joy\": 4,\n","    \"love\": 5,\n","    \"optimism\": 6,\n","    \"pessimism\": 7,\n","    \"sadness\": 8,\n","    \"surprise\": 9,\n","    \"trust\": 10\n","  },\n","  \"transformers_version\": \"4.44.2\",\n","  \"vocab_size\": 6945\n","}"]},"metadata":{},"execution_count":151}]},{"cell_type":"code","source":["model = CustomMLP(config=my_config)\n"],"metadata":{"id":"CNOPoeccsUdc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model"],"metadata":{"id":"0hAOK64RsW_z","colab":{"base_uri":"https://localhost:8080/"},"outputId":"4165fb0e-6c16-4d42-9d7e-561bef9f07af"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["CustomMLP(\n","  (embedding_bag): EmbeddingBag(6945, 300, mode='mean')\n","  (layers): Sequential(\n","    (0): Linear(in_features=300, out_features=200, bias=True)\n","    (1): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU()\n","    (3): Dropout(p=0.5, inplace=False)\n","    (4): Linear(in_features=200, out_features=100, bias=True)\n","    (5): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (6): ReLU()\n","    (7): Dropout(p=0.5, inplace=False)\n","    (8): Linear(in_features=100, out_features=11, bias=True)\n","  )\n",")"]},"metadata":{},"execution_count":153}]},{"cell_type":"code","source":["from sklearn.metrics import f1_score, accuracy_score, classification_report\n","def compute_metrics(eval_pred):\n","    logits, labels = eval_pred\n","    sigmoid_logits = torch.sigmoid(torch.tensor(logits))\n","    predictions = (sigmoid_logits >= 0.5).int().numpy()\n","    labels = labels.astype(int)\n","\n","    f1_micro = f1_score(labels, predictions, average='micro', zero_division=0)\n","    f1_macro = f1_score(labels, predictions, average='macro', zero_division=0)\n","\n","    return {\n","        'f1_micro': f1_micro,\n","        'f1_macro': f1_macro,\n","    }"],"metadata":{"id":"vMOeMMAtsads"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Configure training parameters\n","training_args = TrainingArguments(\n","    num_train_epochs=100,\n","    per_device_train_batch_size=120,  # Adjust if necessary\n","    per_device_eval_batch_size=120,    # Adjust if necessary\n","    weight_decay=0.5,\n","    learning_rate=0.0005,\n","    optim='adamw_torch',\n","    remove_unused_columns=False,\n","\n","    output_dir=str(model_folder),\n","    evaluation_strategy='steps',\n","    eval_steps=200,\n","    save_strategy=\"steps\",\n","    save_steps=200,\n","    load_best_model_at_end=True,\n","    save_total_limit=2,\n","\n","    # Set metric_for_best_model to a multilabel metric like \"f1\" if computed in `compute_metrics`\n","    metric_for_best_model=\"eval_f1_micro\",  # Use F1 score for multilabel classification\n","    greater_is_better=True,\n","\n","    logging_strategy='steps',\n","    logging_steps=200,\n","    report_to='wandb',\n","    run_name='imdb_hf_trainer',\n",")\n"],"metadata":{"id":"FhEFklBMsdbV","colab":{"base_uri":"https://localhost:8080/"},"outputId":"0966c206-ac69-46ec-eac6-d16cbcc80898"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["pip install wandb"],"metadata":{"id":"eoEI86xlsmKK","colab":{"base_uri":"https://localhost:8080/"},"outputId":"2d8ddd0c-cba9-4825-a45b-f4dc1f568579"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (0.18.3)\n","Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n","Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (0.4.0)\n","Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.1.43)\n","Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb) (4.3.6)\n","Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n","Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.2)\n","Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.32.3)\n","Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.16.0)\n","Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb) (1.3.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (71.0.4)\n","Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2024.8.30)\n","Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n"]}]},{"cell_type":"code","source":["trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=trainset,\n","    eval_dataset=validset,\n","    data_collator=collate_fn,  # Make sure this function is correctly handling multilabel data\n","    compute_metrics=compute_metrics,  # Ensure this function computes metrics suitable for multilabel tasks\n",")\n"],"metadata":{"id":"EpQO8NNzsgz8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["trainer.train()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":859},"id":"tUdfuEdJssdy","outputId":"85c54bc8-57eb-495c-dde0-517ae1e2043b"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='5065' max='5200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [5065/5200 04:16 < 00:06, 19.71 it/s, Epoch 97.38/100]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>F1 Micro</th>\n","      <th>F1 Macro</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>200</td>\n","      <td>0.527400</td>\n","      <td>0.482315</td>\n","      <td>0.176925</td>\n","      <td>0.092776</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>0.432100</td>\n","      <td>0.441077</td>\n","      <td>0.384370</td>\n","      <td>0.206478</td>\n","    </tr>\n","    <tr>\n","      <td>600</td>\n","      <td>0.377400</td>\n","      <td>0.410598</td>\n","      <td>0.480533</td>\n","      <td>0.279623</td>\n","    </tr>\n","    <tr>\n","      <td>800</td>\n","      <td>0.339400</td>\n","      <td>0.398941</td>\n","      <td>0.512976</td>\n","      <td>0.331178</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>0.312500</td>\n","      <td>0.396606</td>\n","      <td>0.534067</td>\n","      <td>0.354819</td>\n","    </tr>\n","    <tr>\n","      <td>1200</td>\n","      <td>0.292200</td>\n","      <td>0.396428</td>\n","      <td>0.539832</td>\n","      <td>0.366259</td>\n","    </tr>\n","    <tr>\n","      <td>1400</td>\n","      <td>0.276700</td>\n","      <td>0.399167</td>\n","      <td>0.542104</td>\n","      <td>0.372470</td>\n","    </tr>\n","    <tr>\n","      <td>1600</td>\n","      <td>0.262600</td>\n","      <td>0.401751</td>\n","      <td>0.539358</td>\n","      <td>0.370541</td>\n","    </tr>\n","    <tr>\n","      <td>1800</td>\n","      <td>0.251900</td>\n","      <td>0.408557</td>\n","      <td>0.546599</td>\n","      <td>0.378932</td>\n","    </tr>\n","    <tr>\n","      <td>2000</td>\n","      <td>0.241500</td>\n","      <td>0.410464</td>\n","      <td>0.550902</td>\n","      <td>0.386397</td>\n","    </tr>\n","    <tr>\n","      <td>2200</td>\n","      <td>0.233300</td>\n","      <td>0.414278</td>\n","      <td>0.549032</td>\n","      <td>0.389039</td>\n","    </tr>\n","    <tr>\n","      <td>2400</td>\n","      <td>0.224000</td>\n","      <td>0.420714</td>\n","      <td>0.554964</td>\n","      <td>0.392616</td>\n","    </tr>\n","    <tr>\n","      <td>2600</td>\n","      <td>0.218700</td>\n","      <td>0.423917</td>\n","      <td>0.550344</td>\n","      <td>0.395442</td>\n","    </tr>\n","    <tr>\n","      <td>2800</td>\n","      <td>0.211700</td>\n","      <td>0.426434</td>\n","      <td>0.555024</td>\n","      <td>0.404970</td>\n","    </tr>\n","    <tr>\n","      <td>3000</td>\n","      <td>0.206500</td>\n","      <td>0.431681</td>\n","      <td>0.551314</td>\n","      <td>0.407233</td>\n","    </tr>\n","    <tr>\n","      <td>3200</td>\n","      <td>0.200400</td>\n","      <td>0.435919</td>\n","      <td>0.553674</td>\n","      <td>0.409223</td>\n","    </tr>\n","    <tr>\n","      <td>3400</td>\n","      <td>0.196700</td>\n","      <td>0.443095</td>\n","      <td>0.552269</td>\n","      <td>0.413924</td>\n","    </tr>\n","    <tr>\n","      <td>3600</td>\n","      <td>0.192200</td>\n","      <td>0.442347</td>\n","      <td>0.559498</td>\n","      <td>0.414424</td>\n","    </tr>\n","    <tr>\n","      <td>3800</td>\n","      <td>0.187700</td>\n","      <td>0.447669</td>\n","      <td>0.551468</td>\n","      <td>0.411031</td>\n","    </tr>\n","    <tr>\n","      <td>4000</td>\n","      <td>0.183600</td>\n","      <td>0.451597</td>\n","      <td>0.552957</td>\n","      <td>0.413171</td>\n","    </tr>\n","    <tr>\n","      <td>4200</td>\n","      <td>0.181100</td>\n","      <td>0.457260</td>\n","      <td>0.553593</td>\n","      <td>0.412055</td>\n","    </tr>\n","    <tr>\n","      <td>4400</td>\n","      <td>0.178900</td>\n","      <td>0.460691</td>\n","      <td>0.550557</td>\n","      <td>0.408609</td>\n","    </tr>\n","    <tr>\n","      <td>4600</td>\n","      <td>0.177000</td>\n","      <td>0.465419</td>\n","      <td>0.552515</td>\n","      <td>0.411905</td>\n","    </tr>\n","    <tr>\n","      <td>4800</td>\n","      <td>0.175800</td>\n","      <td>0.465677</td>\n","      <td>0.553146</td>\n","      <td>0.414917</td>\n","    </tr>\n","    <tr>\n","      <td>5000</td>\n","      <td>0.173500</td>\n","      <td>0.463498</td>\n","      <td>0.551787</td>\n","      <td>0.413789</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}}]},{"cell_type":"code","source":["trainer.evaluate()"],"metadata":{"id":"rhm_bSEMtHy1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["valid_output = trainer.predict(validset)"],"metadata":{"id":"33KkQLxEtLEi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["valid_output._fields"],"metadata":{"id":"3d-vjTfYtOmN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["valid_preds = np.argmax(valid_output.predictions, axis=-1)\n","valid_labels = np.array(valid_output.label_ids)"],"metadata":{"id":"Cn1q2wZXB5is"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_df=pd.read_csv(data_folder/'test.csv')"],"metadata":{"id":"lMvqTuWvw82x"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_df['Tweet'] = test_df['Tweet'].apply(clean_text)"],"metadata":{"id":"6EtBAnEmxGgH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sample_X=test_df['Tweet'].values"],"metadata":{"id":"sDUvU2aYxNvl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["device = 'cpu'\n","# Convert the list of texts into a list of lists; each inner list contains the vocabulary indices for a text\n","list_of_list_of_indices = [tokenizer(text, multi_vocab) for text in sample_X]\n","\n","# Compute the offsets for each text in the concatenated tensor\n","offsets = [0] + [len(i) for i in list_of_list_of_indices]\n","offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n","\n","# Concatenate all text indices into a single tensor\n","indices = torch.cat([torch.tensor(i, dtype=torch.int64) for i in list_of_list_of_indices])"],"metadata":{"id":"oAUXrCLrLpIG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# move model to appropriate device\n","model.to(device)\n","\n","# put model in evaluation mode\n","model.eval()\n","\n","# get outputs (logits) from model\n","outputs = model(indices, offsets)\n","outputs"],"metadata":{"id":"q1WfoK3xLyES"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# get predicted labels\n","probabilities = torch.sigmoid(outputs.logits)\n","threshold = 0.5\n","predicted_labels = (probabilities >= threshold).int()\n","no_labels = predicted_labels.sum(1) == 0\n","predicted_labels[no_labels, torch.max(probabilities[no_labels], dim=1).indices] = 1"],"metadata":{"id":"tj5ITdPKxlSs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["binary_predictions = predicted_labels\n","predicted_label_names = []\n","for prediction in binary_predictions:\n","    labels = [model.config.id2label[i] for i, label in enumerate(prediction) if label == 1]\n","    predicted_label_names.append(labels)"],"metadata":{"id":"NWoty9F-MM-E"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["final_df = pd.DataFrame(predicted_labels.numpy(), columns=my_config.id2label.values())\n","final_df.insert(0, 'ID', test_df['ID'])\n","final_df\n"],"metadata":{"id":"wkQHqfN4x_0J"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["final_df.to_csv(data_folder/'result.csv', index=False)"],"metadata":{"id":"SIhyba6ByJSj"},"execution_count":null,"outputs":[]}]}